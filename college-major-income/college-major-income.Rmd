---
title: "College Major & Income"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
runtime: shiny
---

```{r setup, include=FALSE}
library(shiny)
library(reticulate)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

<!-- ## Language {.tabset .tabset-fade} -->

This is Dave's [code](https://github.com/dgrtwo/data-screencasts/blob/master/college-majors.Rmd) behind an analysis of the 538 "College Major and Income" dataset from the [#tidytuesday project](https://github.com/rfordatascience/tidytuesday/tree/master/data/2018/2018-10-16).

# Dependencies {.tabset .tabset-fade}

## R

```{r r-deps, echo=TRUE, message=FALSE}
library(tidyverse)
library(scales)
library(ggrepel)
library(plotly)
theme_set(theme_light())
```

## Python

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import seaborn as sns

pd.set_option('display.max_columns', 500)
```

# Reading data {.tabset .tabset-fade}

## R

```{r echo=TRUE}
recent_grads <- read_csv("recent-grads.csv")
head(recent_grads)
```

## Python

```{python}
recent_grads = pd.read_csv("recent-grads.csv") # side note: entering direct raw github url resulted in some parser error.
recent_grads.head()
```

# Data cleaning {.tabset .tabset-fade}

## R

```{r}
# cleaning step
major_processed <- recent_grads %>%
    arrange(desc(Median)) %>%
    # change all caps to words with first letter capitalized
    mutate(Major = str_to_title(Major), 
        Major = fct_reorder(Major, Median))
head(major_processed[c('Major', 'Median')], 15)
```

## Python

```{python}
import string
major_processed = recent_grads.sort_values(by='Median', ascending=False)
# mutate(Major = str_to_title(Major), -> use pandas apply w. string.capwords
#         Major = fct_reorder(Major, Median)) -> just subset w. [ using -Median and index with the sorted indices
major_processed['Major'] = major_processed['Major'].apply(string.capwords)[(-major_processed['Median']).argsort()]
# Gotcha: argsort() will mess up row index order for tied Median, even setting the kind param of argsort didn't work
major_processed.sort_index(inplace = True)
major_processed[['Major', 'Median']].head(15)
```

# Aggregating by category {.tabset .tabset-fade}

## R
```{r}
head(major_processed[c('Major', 'Median')], 10)
# Common pattern: group_by -> summarize -> arrange
by_major_category <- major_processed %>%
    filter(!is.na(Total)) %>%
    group_by(Major_category) %>%
    # summarize is nice when you need to apply different functions to columns
    summarize(Men = sum(Men),
              Women = sum(Women),
              Total = sum(Total),
              # weight the medians by sample size
              MedianSalary = sum(Median * Sample_size) / sum(Sample_size)) %>%
    mutate(ShareWomen = Women / Total) %>%
    arrange(desc(ShareWomen))
by_major_category
```

## Python
```{python}
# R -> pandas challenge (help!):
# There might be a better way to do this, but can't figure out how MedianSalary and ShareWomen can be 
# declared within the agg() like you could with R's summerise

# Workaround (which is actually fewer lines):
# For now, setting with breaking things up into statements
by_major_category_grp = major_processed[major_processed.Total.notnull()].groupby('Major_category')
# Do the groupby / sum on the Men, Women, Total
by_major_category = by_major_category_grp['Men', 'Women', 'Total'].sum()
# Before creating the MedianSalary column.
by_major_category['MedianSalary'] =  by_major_category_grp.apply(lambda x: sum(x.Median * x.Sample_size) / sum(x.Sample_size))
# Transform ShareWomen
by_major_category['ShareWomen'] = by_major_category['Women'] / by_major_category['Total']
by_major_category.sort_values('ShareWomen', ascending=False, inplace=True)
by_major_category
```

# What categories of majors make more money than others?  {.tabset .tabset-fade}


## R
```{r}
# visualize the distribution of salary for each major using boxplot
major_processed %>%
    # reorder Major_category according to the Median (top -> highest salary)
    mutate(Major_category = fct_reorder(Major_category, Median)) %>%
    # Major_category as X, Median as y
    ggplot(aes(Major_category, Median, fill = Major_category)) +
    geom_boxplot() +
    # reformats the Median (y) as currency in $
    scale_y_continuous(labels = dollar_format()) +
    # since it's hard to read the labels for x axis, flip coords
    expand_limits(y = 0) +
    coord_flip() +
    theme(legend.position = "none")

major_processed %>%
    # reorder Major_category according to the Median (top -> highest salary)
    mutate(Major_category = fct_reorder(Major_category, Median)) %>%
    select(Major, Major_category, Median) 
```

## Python
```{python warning = FALSE, message = FALSE}
major_processed_dist_salary = major_processed.copy()
# reorder Major_category according to the Median (top -> highest salary)
# I'm sure there's a better way, but one way to replicate `fct_reorder` is to do a groupby -> agg -> sort_values
cat_order = major_processed_dist_salary.groupby('Major_category').agg('median').sort_values('Median', ascending=False).index.values.tolist()
# seaborn/matplotlib why are you like this? are there better ways?
# limitations: there isn't an equivalent expand_limits so I had to use xlim and set the proper upper bound to include 
# the Engineering outlier
_ = plt.xlim(0, major_processed_dist_salary['Median'].max() + 1000)
ax = sns.boxplot(
      x = 'Median',
      y = 'Major_category', 
      data = major_processed_dist_salary,
      order = cat_order)
_ = ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('$%1.f'))
plt.tight_layout()
plt.show()
```

<!-- ## What are the highest earning majors?  -->

<!-- ```{r major_highest_earning, fig.width=10} -->
<!-- major_processed %>% -->
<!--     filter(Sample_size >= 100) %>% -->
<!--     head(20) %>% -->
<!--     ggplot(aes(Major, Median, color=Major_category)) + -->
<!--     geom_point() +  -->
<!--     # show intervals (range of salaries) -->
<!--     geom_errorbar(aes(ymin = P25th, ymax = P75th)) + -->
<!--     # geom_point doesn't start at 0 whereas geom_col does -->
<!--     # so need to expand scale to start from 0 -->
<!--     expand_limits(y = 0) +  -->
<!--     scale_y_continuous(labels = dollar_format()) + -->
<!--     coord_flip() + -->
<!--     labs(title = "What are the highest earning majors?",  -->
<!--         subtitle = "Top 20 majors with at least a 100 graduates surveyed. Bars represent the 25th to 75th percentile.", -->
<!--         x = "", -->
<!--         y = "Median salary of graduates") -->
<!-- ``` -->

<!-- ## How does gender breakdown relate to typical earnings? -->

<!-- ```{r} -->
<!-- major_processed %>% -->
<!--     arrange(desc(Total)) %>% -->
<!--     head(20) %>% -->
<!--     mutate(Major = fct_reorder(Major, Total)) %>% -->
<!--     # `gather` will collapse the two columns (Women, Men) into a single Gender column where value is n  -->
<!--     # extra observations are added to df as a consequence -->
<!--     gather(Gender, Number, Women, Men) %>% -->
<!--     ggplot(aes(Major, Number, fill = Gender)) + -->
<!--     scale_y_continuous(labels = comma_format()) + -->
<!--     geom_col() + -->
<!--     coord_flip() -->
<!-- ``` -->

<!-- ```{r fig.width=8} -->
<!-- g <- major_processed %>% -->
<!--     mutate(Major_category = fct_lump(Major_category, 4)) %>%  -->
<!--     # the size gives a sense of what is a outlier or not -->
<!--     ggplot(aes(ShareWomen, Median, color = Major_category, size = Sample_size, label = Major)) + -->
<!--     geom_point() + -->
<!--     scale_x_continuous(labels = percent_format()) + -->
<!--     scale_y_continuous(labels = dollar_format()) + -->
<!--     geom_smooth(aes(group = 1), method = "lm") + -->
<!--     expand_limits(y = 0) -->
<!-- # interactive graph to show each one of the aes -->
<!-- ggplotly(g) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # every percentage pt a field is male, the expected salary would decrease by 23650 / 100 => ~$237 -->
<!-- major_processed %>% -->
<!--     select(Major, Total, ShareWomen, Sample_size, Median) %>% -->
<!--     # linear model; Median explained by ShareWomen -->
<!--     # weighted linear regression with extra weight param -->
<!--     # it tells lm that for e.g. Petroleum Engr. > Metallurgical Engr. in Sample_size -->
<!--     lm(Median ~ ShareWomen, data = ., weights = Sample_size) %>% -->
<!--     summary() -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # woa there -->
<!-- library(broom) -->
<!-- major_processed %>%  -->
<!--   select(Major, Major_category, Total, ShareWomen, Sample_size, Median) %>%  -->
<!--   # dplyr  -->
<!--   add_count(Major_category) %>%  -->
<!--   filter(n >= 10) %>%  -->
<!--   nest(-Major_category) %>%  -->
<!--   mutate(model = map(data, ~ lm(Median ~ ShareWomen, data = ., weights = Sample_size)), -->
<!--          tidied = map(model, tidy)) %>%  -->
<!--   unnest(tidied) %>%  -->
<!--   filter(term == "ShareWomen") %>%  -->
<!--   arrange(estimate) %>%  -->
<!--   mutate(fdr = p.adjust(p.value, method = "fdr")) -->
<!-- ``` -->

<!-- ### Appendix -->


<!-- ```{r} -->
<!-- major_processed %>% -->
<!--     filter(Sample_size >= 100) %>% -->
<!--     ggplot(aes(Sample_size, Median)) + -->
<!--     geom_point() + -->
<!--     geom_text(aes(label = Major), check_overlap = TRUE, vjust = 1, hjust = 1) + -->
<!--     scale_x_log10() -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # this is so that the rest of the Rmd gets ignored  -->
<!-- knitr::knit_exit() -->
<!-- ``` -->

<!-- Scrap -->

<!-- ```{r} -->
<!-- major_processed %>%  -->
<!--   filter(Sample_size >= 100) %>%  -->
<!--   mutate(IQR = P75th - P25th) %>%  -->
<!--   arrange(desc(IQR)) %>%  -->
<!--   View() -->
<!-- ``` -->


<!-- ## Most common major -->

<!-- What were the most common **majors**? (since there were 173 we're only showing some) -->

<!-- ```{r common_majors, fig.width=10} -->
<!-- major_processed %>% -->
<!--     mutate(Major = fct_reorder(Major, Total)) %>% -->
<!--     arrange(desc(Total)) %>% -->
<!--     head(20) %>% -->
<!--     ggplot(aes(Major, Total, fill = Major_category)) + -->
<!--     geom_col() + -->
<!--     coord_flip() + -->
<!--     scale_y_continuous(labels = comma_format()) + -->
<!--     labs(x = "", -->
<!--         y = "Total # of graduates") -->
<!-- ``` -->

<!-- ## Most common major categories -->

<!-- What major categories were most common? -->

<!-- ```{r} -->
<!-- major_processed %>% -->
<!--     count(Major_category, wt = Total, sort = TRUE) %>% -->
<!--     mutate(Major_category = fct_reorder(Major_category, n)) %>% -->
<!--     ggplot(aes(Major_category, n, fill = Major_category)) + -->
<!--     geom_col() + -->
<!--     coord_flip() + -->
<!--     labs(x = "", -->
<!--         y = "Total # of graduates") + -->
<!--     theme(legend.position = "none") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # visualize the distribution of salary for each major using bar -->
<!-- major_processed %>% -->
<!--     group_by(Major_category) %>% -->
<!--     summarize(Median = median(Median)) %>% -->
<!--     mutate(Major_category = fct_reorder(Major_category, Median)) %>% -->
<!--     ggplot(aes(Major_category, Median)) + -->
<!--     geom_col() + -->
<!--     scale_y_continuous(labels = dollar_format()) + -->
<!--     coord_flip() -->
<!-- ``` -->

<!-- ## What are the lowest earning majors? -->

<!-- ```{r major_lowest_earning, fig.width=10} -->
<!-- major_processed %>% -->
<!--     filter(Sample_size >= 100) %>% -->
<!--     tail(20) %>% -->
<!--     ggplot(aes(Major, Median, color=Major_category)) + -->
<!--     geom_point() +  -->
<!--     # show intervals (range of salaries) -->
<!--     geom_errorbar(aes(ymin = P25th, ymax = P75th)) + -->
<!--     # geom_point doesn't start at 0 whereas geom_col does -->
<!--     # so need to expand scale to start from 0 -->
<!--     expand_limits(y = 0) +  -->
<!--     coord_flip() + -->
<!--     labs(title = "What are the lowest earning majors?",  -->
<!--         subtitle = "Bottom 20 majors with at least a 100 graduates surveyed. Bars represent the 25th to 75th percentile.", -->
<!--         x = "", -->
<!--         y = "Median salary of graduates") -->
<!-- ``` -->

